# ğŸ”¥ AnÃ¡lisis de OptimizaciÃ³n de Tokens - Tagers KISS API

**Fecha:** 2026-01-14  
**Estado actual:** 3-9 llamadas de AI por mensaje  
**Objetivo:** 1 llamada de AI por mensaje (o 0 si hay cache hit)  
**Ahorro estimado:** 70-85% de costos de AI

---

## 1. DIAGNÃ“STICO DEL PROBLEMA

### 1.1 Flujo Actual (Agentic Flow)

```
MENSAJE ENTRANTE
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DISPATCHER (regex) â†’ Decide si va a Agentic Flow           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼ (Si no es trivial)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ANALYZER (gpt-5.2) ğŸ”´                                       â”‚
â”‚  - Analiza intent                                            â”‚
â”‚  - Detecta frustraciÃ³n                                       â”‚
â”‚  - Detecta loops                                             â”‚
â”‚  Prompt: ~2.5KB | Tokens output: ~1800                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RETRIEVER (cÃ³digo)                                          â”‚
â”‚  - Busca en pgvector                                         â”‚
â”‚  - Prepara contexto                                          â”‚
â”‚  - No consume tokens de AI                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GENERATOR (gpt-5.2) ğŸ”´                                      â”‚
â”‚  - Genera respuesta                                          â”‚
â”‚  - Incluye todo el contexto                                  â”‚
â”‚  Prompt: ~10KB | Tokens output: ~3000                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VALIDATOR (gpt-5.2) ğŸ”´                                      â”‚
â”‚  - Valida calidad                                            â”‚
â”‚  - Puede pedir revisiÃ³n                                      â”‚
â”‚  Prompt: ~3KB | Tokens output: ~1500                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼ (Si needs_revision, repite hasta 3 veces)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GENERATOR (gpt-5.2) ğŸ”´ + VALIDATOR (gpt-5.2) ğŸ”´            â”‚
â”‚  x1, x2, x3...                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Consumo por Mensaje

| Paso | Modelo | Tokens Input | Tokens Output | Costo Estimado |
|------|--------|--------------|---------------|----------------|
| Analyzer | gpt-5.2 | ~3000 | ~500 | ~$0.012 |
| Generator | gpt-5.2 | ~12000 | ~800 | ~$0.040 |
| Validator | gpt-5.2 | ~4000 | ~400 | ~$0.015 |
| **TOTAL (mÃ­nimo)** | | ~19000 | ~1700 | **~$0.067** |
| **TOTAL (con revisiones)** | | ~35000 | ~3000 | **~$0.120** |

**Costo estimado por 1000 mensajes: $67 - $120 USD**

### 1.3 Problemas Identificados

1. **Modelos sobredimensionados**
   - Usando gpt-5.2 (el mÃ¡s caro) para TODAS las tareas
   - ClasificaciÃ³n simple no necesita el modelo mÃ¡s inteligente

2. **Llamadas redundantes**
   - Analyzer analiza intent â†’ pero Dispatcher YA lo hizo con regex
   - Validator valida calidad â†’ pero un buen prompt produce buena calidad
   - 3 pasos que podrÃ­an ser 1

3. **Prompts inflados**
   - `chatwoot_router_system.md`: 6KB de ejemplos
   - Mucha redundancia y repeticiÃ³n
   - Historia de conversaciÃ³n enviada completa en cada llamada

4. **Sin short-circuit efectivo**
   - Semantic cache existe pero no se usa en el flujo principal
   - Respuestas canned pasan por Generator+Validator aunque ya estÃ¡n listas

---

## 2. SOLUCIÃ“N PROPUESTA

### 2.1 Nuevo Flujo Simplificado

```
MENSAJE ENTRANTE
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FAST PATH (cÃ³digo + regex)                                  â”‚
â”‚  - Saludos, despedidas, gracias â†’ Respuesta directa          â”‚
â”‚  - Handoff explÃ­cito â†’ Escalar                               â”‚
â”‚  - Flujo activo â†’ Continuar flujo                            â”‚
â”‚  âš¡ 0 llamadas AI                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼ (Si no es fast path)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SEMANTIC CACHE CHECK                                        â”‚
â”‚  - Buscar pregunta similar (>0.85 similitud)                 â”‚
â”‚  - Si encontrada â†’ Respuesta del cache                       â”‚
â”‚  âš¡ 0 llamadas AI                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼ (Si no hay cache hit)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CANNED RESPONSE CHECK (pgvector)                            â”‚
â”‚  - Buscar respuesta predefinida (>0.90 similitud)            â”‚
â”‚  - Si encontrada â†’ Usar directamente                         â”‚
â”‚  âš¡ 0 llamadas AI                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼ (Si necesita AI)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SINGLE AI CALL (gpt-5-mini) âœ…                              â”‚
â”‚  - Prompt compacto (~2KB)                                    â”‚
â”‚  - Contexto mÃ­nimo necesario                                 â”‚
â”‚  - Historia resumida (no completa)                           â”‚
â”‚  âš¡ 1 llamada AI                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CACHE RESPONSE                                              â”‚
â”‚  - Guardar en semantic cache                                 â”‚
â”‚  - Disponible para futuras preguntas similares               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Consumo Optimizado por Mensaje

| Escenario | Llamadas AI | Tokens Input | Tokens Output | Costo Est. |
|-----------|-------------|--------------|---------------|------------|
| Fast path (40% mensajes) | 0 | 0 | 0 | $0 |
| Cache hit (30% mensajes) | 0 | 0 | 0 | $0 |
| Canned match (15% mensajes) | 0 | 0 | 0 | $0 |
| AI necesario (15% mensajes) | 1 | ~4000 | ~500 | ~$0.008 |
| **PROMEDIO** | 0.15 | ~600 | ~75 | **~$0.0012** |

**Costo estimado por 1000 mensajes: ~$1.20 USD**

### 2.3 Ahorro

| MÃ©trica | Actual | Optimizado | Ahorro |
|---------|--------|------------|--------|
| Llamadas AI / mensaje | 3-9 | 0.15 | **95%** |
| Tokens input / mensaje | 19000-35000 | ~600 | **97%** |
| Costo / 1000 mensajes | $67-120 | ~$1.20 | **98%** |

---

## 3. CAMBIOS TÃ‰CNICOS

### 3.1 Actualizar `model_policy.json`

```json
{
  "tasks": {
    "tania_reply_simple": {
      "model": "gpt-5-mini",  // Cambio de gpt-5.2
      "max_output_tokens": 800,
      "temperature": 0.3
    },
    "tania_reply_complex": {
      "model": "gpt-5.2",  // Solo para casos complejos
      "max_output_tokens": 1500,
      "temperature": 0.3
    }
  }
}
```

### 3.2 Crear `agentic_flow_optimized.js`

Ver archivo adjunto: Flujo simplificado con 1 llamada.

### 3.3 Crear `prompt_tania_compact.md`

Prompt reducido de 3.3KB a ~1KB.

### 3.4 Actualizar `dispatcher.js`

Agregar checks de cache y canned responses antes de delegar.

---

## 4. MÃ‰TRICAS DE Ã‰XITO

1. **Llamadas AI por mensaje**: < 0.3 promedio
2. **Cache hit rate**: > 40%
3. **Costo por 1000 mensajes**: < $5 USD
4. **Latencia P95**: < 500ms (vs 2-5s actual)
5. **Calidad de respuestas**: Mantener o mejorar (medido por thumbs up/down)

---

## 5. PLAN DE IMPLEMENTACIÃ“N

### Fase 1: Quick Wins (1-2 horas)
- [ ] Cambiar modelos de gpt-5.2 a gpt-5-mini para Analyzer y Validator
- [ ] Desactivar Validator (flag en env)
- [ ] Reducir MAX_REVISIONS a 1

### Fase 2: OptimizaciÃ³n Core (4-6 horas)
- [ ] Implementar semantic cache check en dispatcher
- [ ] Implementar canned response short-circuit
- [ ] Crear prompt compacto

### Fase 3: Flujo Simplificado (8 horas)
- [ ] Crear agentic_flow_optimized.js
- [ ] Eliminar Analyzer redundante
- [ ] Combinar lÃ³gica en una sola llamada

### Fase 4: Monitoreo
- [ ] Dashboard de token usage
- [ ] Alertas de regresiÃ³n de calidad
- [ ] A/B testing nuevo vs viejo

---

## 6. RIESGOS Y MITIGACIÃ“N

| Riesgo | MitigaciÃ³n |
|--------|------------|
| Menor calidad de respuestas | A/B testing, rollback fÃ¡cil |
| Cache sirve respuestas obsoletas | TTL cortos, invalidaciÃ³n por categorÃ­a |
| gpt-5-mini no es suficiente | Escalamiento dinÃ¡mico a gpt-5.2 por complejidad |

---

## CONCLUSIÃ“N

El sistema actual gasta 50-100x mÃ¡s tokens de lo necesario. Con las optimizaciones propuestas:

- **Costo mensual**: De ~$2000-4000 a ~$50-100
- **Latencia**: De 2-5s a <500ms
- **Calidad**: Igual o mejor (prompts mÃ¡s focalizados)

La clave es: **usar AI solo cuando realmente lo necesitas**.
